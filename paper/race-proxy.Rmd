---
title: "Consistent Estimation of Racial Disparities when Race is Not Observed"
author: 
date: '`r format(Sys.Date(), "%B %e, %Y")`'
abstract: |
    Abstract here.
keywords: 
    - keyword 1
    - keyword 2
bibliography: references.bib
biblio-style: apalike
output:
    bookdown::pdf_document2:
        template: "template.tex"
        number_sections: true
        keep_tex: true
        includes: 
            in_header: "header.tex"
        latex_engine: pdflatex
editor_options: 
    markdown: 
        wrap: sentence
---

```{r setup, include=FALSE}
library(knitr)
library(here)

opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE,
               fig.path=here("paper/figures/"), fig.align="center",
               fig.width=(8.5-2*1)/2, out.width="100%", fig.asp=0.8)
```

# Introduction

# Problem

```{=tex}
\begin{figure}[h]
\begin{center}
    \tikzstyle{main node}=[circle,draw,font=\sffamily\Large\bfseries]
    \tikzstyle{sub node}=[circle,draw,dashed,font=\sffamily\Large\bfseries]
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3cm,thick]
    
        \node[main node] (G) {$G$};
        \node[main node] (R) [below of=G] {$R$};
        \node[main node] (S) [below left=1cm and 1cm of R] {$S$};
        \node[main node] (X) [right of=G] {$X$};
        \node[main node] (Z) [below of=X] {$Z$};
        \node[main node] (Y) [below right=0.5cm and 1cm of X] {$Y$};
        
        \path[every node/.style={font=\sffamily\small}]
        (R) edge node  {} (G)
        (R) edge node  {} (Z)
        (R) edge node  {} (X)
        (R) edge node  {} (S)
        (G) edge [dashed] node  {} (S)
        (G) edge node  {} (Z)
        (G) edge node  {} (X)
        (Z) edge node  {} (X)
        (Z) edge node  {} (Y)
        (Z) edge [dashed] node  {} (S)
        (X) edge node  {} (Y);
    \end{tikzpicture}
\end{center}
\caption{DAG}
\label{fig:dag}
\end{figure}
```
-   $R_i\in \cR$: race
-   $X_i\in\cX$: outcome (may depend on race)
-   $Y_i\in\cY$: algorithmic outcome (does not depend on race)
-   $G_i\in\cG$: location of residence
-   $Z_i\in\cZ$: other covariates
-   $S_i\in\cS$: surname

The above DAG implies the following conditional independence relations:

-   $S\indep X\mid R$ (without dashed lines)
-   $S\indep X\mid R,G,Z$ (with dashed lines)
-   $Y\indep R\mid X, Z$

# Model

## General model

From the DAG shown in Figure \@ref(fig:dag), we can write down the following fully saturated model.
\begin{align*}
    X_i \mid R_i, G_i, Z_i, \Theta &\sim \Categorical_\cX(\vb*\theta_{\cdot R_i}(G_i,Z_i)) \\
    (G_i, Z_i) \mid R_i &\sim \Categorical_{\cG\times\cZ}(\vb p_{GZ|R_i}) \\
    S_i \mid R_i &\sim \Categorical_\cS(\vb p_{S|R_i}) \\
    R_i &\sim \Categorical_\cR(\vb p_R) \\
    \Theta &\sim \pi(\Theta)
\end{align*}
The parameter $\Theta$ can be viewed as a matrix of functions, with each entry $\theta_{xr}$ mapping values of $G$ and $Z$ to a conditional probability $\Pr(X=x\mid R=r, G=g, Z=z)$.

Our primary quantity of interest is the marginalized parameter $$
    \bar\Theta = \sum_{g\in\cG,z\in\cZ} \Theta(g, z) p_{gz},
$$ the conditional distribution of $X$ given $R$.
Here $p_{gz}$ are the marginal probabilities of every $(g, z)$ combination in our population of interest.

The posterior is then

\begin{align*}
    \pi(\Theta, \vb R\mid \vb X, \vb G, \vb Z, \vb S)
    &\propto \pi(\Theta)\prod_{i=1}^N \pi(X_i\mid G_i, Z_i, R_i, \Theta)
            \pi(G_i, Z_i\mid R_i)\pi(S_i\mid R_i)\pi(R_i) \\
    &= \pi(\Theta) \prod_{i=1}^N \theta_{X_iR_i}(G_i, Z_i) p_{G_iZ_i\mid R_i} p_{S_i\mid R_i} p_{R_i} \\
    &= \pi(\Theta) \prod_{i=1}^N \theta_{X_iR_i}(G_i, Z_i)\hat{r_i}_{R_i},
\end{align*} where we let $\hat{\vb r}_i\dfeq \vb p_{G_iZ_i\mid R} \circ \vb p_{S_i\mid R} \circ \vb p_{R}$ denote the vector of BISGZ race probabilities, which depend on external data represented in $\vb p_{GZ\mid R}$, $\vb p_{S\mid R}$, and $\vb p_R$, but not on the parameters $\Theta$ and $\vb R$.

## Marginalized Posterior

Since $\vb R$ is high-dimensional, discrete, and not of primary interest, we marginalize it out to improve sampling:
\begin{align*}
    \pi(X_i,G_i,Z_i,S_i\mid \Theta)
    &\propto \sum_{r\in\cR} \pi(X_i,R_i,G_i,Z_i,S_i\mid \Theta) \\
    &= \sum_{r\in\cR} \theta_{X_i r}(G_i, Z_i)\hat{r}_{ir} 
    = \vb*\theta_{X_i}(G_i, Z_i)^\top \hat{\vb r}_i.
\end{align*}
So the marginalized posterior is
\begin{align}
    \pi(\Theta\mid \vb X, \vb G, \vb Z, \vb S)
    &= \pi(\Theta) \prod_{i=1}^N \vb*\theta_{X_i}(G_i, Z_i)^\top \hat{\vb r}_i.
    \label{eq:post-marg}
\end{align}

## Prior on $\Theta$


# Error and Bias

The primary source of error in the model \eqref{eq:post-marg} comes from inaccurate input tables $\vb p_{GZ\mid R}$, $\vb p_{S\mid R}$, and $\vb p_R$.
We can consider the "true" values of these tables, which would yield "true" individual race probabilities $\vb r^*_i$.
The question then becomes one of quantifying how a particular error in these probabilities $\vb r^*_i - \hat{\vb r}_i$ translates into error in the posterior.

Denote by $\pi^*$ the posterior constructed using the $\vb r^*_i$. 
Then for a particular quantity of interest $g(\Theta)$, we can write the relative absolute error as \[
    \mathrm{RAE}_{\pi^*}(g) \dfeq \qty|\frac{\E_{\pi^*}[g(\Theta)] 
    - \E_{\pi}[g(\Theta)]}{\mathrm{sd}_{\pi}[g(\Theta)]}|,
\]

Let $\vb*\delta_i^* \dfeq \vb r^*_i - \hat{\vb r}_i$, and notice that $\ind^\top\vb*\delta_i=0$ and all $\delta_{ij}\in[-1,1]$.
Define perturbation weights \[
    w(\Theta,\vb*\delta^*) \dfeq 
    \prod_{i=1}^N 
    \qty(1 + \frac{\vb*\theta_{X_i}(G_i, Z_i)^\top \vb*\delta_i^*}{
    \vb*\theta_{X_i}(G_i, Z_i)^\top \hat{\vb r}_i})
    \propto \frac{\pi^*(\Theta\mid\vb X,\vb G,\vb Z,\vb S)}{\pi(\Theta\mid\vb X,\vb G,\vb Z,\vb S)}.
\] 

From Theorem 4 of @weiss1996approach, we can bound $\mathrm{RAE}(g)$ with the variance of these perturbation weights after normalization, which is also the $\chi^2$-divergence between $\pi^*$ and $\pi$: \[
    \mathrm{RAE}_{\pi^*}(g)^2  \le \chi^2(\pi^*) 
    = \frac{\E_\pi[w(\Theta,\vb*\delta^*)^2]}{\E_\pi[w(\Theta,\vb*\delta^*)]^2} - 1
\]

Since we don't know $\vb r^*_i$, we will focus on deriving a worst-case bound on $\chi^2(\pi^*)$ in terms of the average size of the $\vb*\delta_i^*$, measured as \[
    \Delta^* = \sqrt{\sum_{i=1}^N\sum_{j\in\cR} {\delta_{ij}^*}^2}.
\]

We'll first simplify the problem by moving the supremum to the inside: if $\Delta^*\le \eps$, then
\begin{align*}
    \chi^2(\pi^*) \le \sup_{\Delta=\eps}
        \frac{\E_\pi[w(\Theta,\vb*\delta)^2]}{\E_\pi[w(\Theta,\vb*\delta)]^2} - 1 
    \le \E_\pi\qty[\sup_{\Delta=\eps} \qty(\frac{w(\Theta,\vb*\delta)}{
        \E_\pi[w(\Theta,\vb*\delta)]})^2] - 1 \\
    = \E_\pi\qty[\exp \qty(2\cdot\sup_{\Delta=\eps}(
        \log w(\Theta,\vb*\delta) - \log\E_\pi[w(\Theta,\vb*\delta)]))] - 1.
        \numberthis\label{eq:sup-simp}
\end{align*}

We can leverage the inequality $\log(1+x)\le x$ to upper-bound the first term inside the supremum:
\begin{align*}
    \log w(\theta,\vb*\delta) 
    &= \sum_{i=1}^N \log(1 + \frac{\vb*\theta_{X_i}(G_i, Z_i)^\top \vb*\delta_i}{
        \vb*\theta_{X_i}(G_i, Z_i)^\top \hat{\vb r}_i}) \\
    &\le \sum_{i=1}^N \frac{\vb*\theta_{X_i}(G_i, Z_i)^\top \vb*\delta_i}{
        \vb*\theta_{X_i}(G_i, Z_i)^\top \hat{\vb r}_i}.
\end{align*}

For the second term, the opposite inequality $\frac{x}{1+x}\le \log(1+x)$ yields
\begin{align*}
    \log \E_\pi w(\Theta,\vb*\delta) &\ge \E_\pi \log w(\Theta,\vb*\delta) \\
    &= \sum_{i=1}^N \E_\pi \log(1 + \frac{\vb*\theta_{X_i}(G_i, Z_i)^\top \vb*\delta_i}{
        \vb*\theta_{X_i}(G_i, Z_i)^\top \hat{\vb r}_i}) \\
    &\ge \sum_{i=1}^N \E_\pi\qty[
        \frac{\vb*\theta_{X_i}(G_i, Z_i)^\top \vb*\delta_i}{
        \vb*\theta_{X_i}(G_i, Z_i)^\top \hat{\vb r}_i + 
            \vb*\theta_{X_i}(G_i, Z_i)^\top \vb*\delta_i}] \\
    &\le \sum_{i=1}^N \E_\pi\qty[
        \frac{\vb*\theta_{X_i}(G_i, Z_i)^\top \vb*\delta_i}{
        \norm{\vb*\theta_{X_i}(G_i, Z_i)}\norm{\hat{\vb r}_i + \vb*\delta_i}}]
    \le \sum_{i=1}^N \E_\pi\qty[
        \frac{\vb*\theta_{X_i}(G_i, Z_i)^\top \vb*\delta_i}{
        \norm{\vb*\theta_{X_i}(G_i, Z_i)}}].
\end{align*}

Combining these results,
\begin{align*}
    \log w(\theta,\vb*\delta) - \log \E_\pi w(\Theta,\vb*\delta) 
    &\le \sum_{i=1}^N \qty(
        \frac{\vb*\theta_{X_i}(G_i, Z_i)^\top}{
        \vb*\theta_{X_i}(G_i, Z_i)^\top \hat{\vb r}_i} -
        \E_\pi\qty[
        \frac{\vb*\theta_{X_i}(G_i, Z_i)^\top}{
            \norm{\vb*\theta_{X_i}(G_i, Z_i)}}])  \vb*\delta_i \\
    &\le \Delta \sqrt{\sum_{i=1}^N \norm{
        \frac{\vb*\theta_{X_i}(G_i, Z_i)}{
        \vb*\theta_{X_i}(G_i, Z_i)^\top \hat{\vb r}_i} -
        \E_\pi\qty[
        \frac{\vb*\theta_{X_i}(G_i, Z_i)}{
            \norm{\vb*\theta_{X_i}(G_i, Z_i)}}]}^2} \\
\end{align*}

Finally, substituting into \eqref{eq:sup-simp} and taking a square root, \[
    \mathrm{RAE}_{\pi^*}(g) \le  \sqrt{\E_\pi
    \exp\qty(\eps^2\sum_{i=1}^N \norm{
        \frac{\vb*\theta_{X_i}(G_i, Z_i)}{
        \vb*\theta_{X_i}(G_i, Z_i)^\top \hat{\vb r}_i} -
        \E_\pi\qty[
        \frac{\vb*\theta_{X_i}(G_i, Z_i)}{
            \norm{\vb*\theta_{X_i}(G_i, Z_i)}}]}^2) - 1}
\]


# References {-}
