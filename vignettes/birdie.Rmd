---
title: "Estimation of Racial Disparities when Race is Not Observed"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Estimation of Racial Disparities when Race is Not Observed}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This document will walk you through how to use `birdie`. First, load in the package.

```{r setup, message=FALSE}
library(birdie)
library(dplyr)
```

For a concrete example, we'll use some fake voter file data.
Our goal is to estimate turnout rates by race.

```{r}
data(pseudo_vf)

print(pseudo_vf)
```

You'll notice that we have a `race` column in our data.
That will allow us to check our work once we're done.
For now, we'll generate the *true* distribution of turnout and race, along with the marginal distribution of each variable.

```{r}
p_xr = prop.table(table(pseudo_vf$turnout, pseudo_vf$race))
p_x = rowSums(p_xr)
p_r = colSums(p_xr)
```

There are two steps to applying the `birdie` methodology:

1. Generate a first set of individual race probabilities using Bayesian Improved Surname Geocoding (`bisg()`).
1. For a specific outcome variable of interest, run a Bayesian Instrumental Regression for Disparity Estimation (`birdie()`) model to come up with estimated probabilities conditional on race.

## Generating BISG probabilities

For the first step, you can use any BISG software, including the [`wru` R package](https://cran.r-project.org/package=wru).
However, `birdie` provides its own `bisg()` function to make this easy and very computationally efficient.
To use `bisg()`, you provide a formula that labels the predictors used.
You use `nm()` to show which variable contains last names, which must always be provided.
ZIP codes and states can be labeled with `zip()` and `state()`.
Other types of geographies can be used as well---just read the documentation for `bisg()`.

```{r}
r_probs = bisg(~ nm(last_name) + zip(zip), data=pseudo_vf, p_r=p_r)
print(r_probs)
```

Each row `r_probs` matches a row in `pseudo_vf`.
It's important to note that here we are assuming that we know the overall racial distribution of our population (registered voters).
Because of that, we provide the `p_r=p_r` argument, which gives `bisg()` the overall racial distribution.
If you don't know the overall racial distribution in your context (even a guess is better than nothing), then you could pass in something like the national distribution of race (which is conveniently provided by `p_r_natl()`).

## Estimating distributions by race

We're now ready to estimate turnout by race.
For this we'll use the `birdie()` function, and provide it with a formula describing our BIRDiE model, including our variable of interest `turnout` and our geography variable `zip`.
`birdie()` knows how to handle the columns of `r_probs` because they came from this package.
If you use a different package, the columns may be named differently.
The `prefix` parameter to `birdie()` lets you specify the naming convention for your probabilities.

```{r}
fit = birdie(r_probs, turnout ~ zip, data=pseudo_vf)
print(fit)
```

<!--
The `fit` object has a lot of diagnostic information.

```{r}
str(fit)
```

The arrays stored in `fit$draws` contains the actual estimates of the distribution of our outome given race.
Since `birdie` fits a Bayesian model, we have one set of estimates for every random draw from our posterior.
You are encouraged to use all of these draws, as they capture the uncertainty inherent in the estimation.
For a  quick summary, you can take the mean across draws.

## Evaluating estimates

To evaluate the turnout estimates, we'll first convert them into a single best guess of the *joint* distribution of turnout and race.
`birdie` provides the `calc_joint_bisgz()` and `calc_joint_model()` functions to do this; the former computes weighted averages using the BISG probabilities, and the latter converts  the estimated conditional distribution into a joint one.
You can use `calc_joint_model()` to build a credible interval around your estimates by passing in different quantiles to the second argument.

```{r}
xr = list(
    true = p_xr,
    weight = calc_joint_bisgz(r_probs, pseudo_vf$turnout, method="weight"),
    thresh = calc_joint_bisgz(r_probs, pseudo_vf$turnout, method="thresh"),
    mi = calc_joint_bisgz(r_probs, pseudo_vf$turnout, method="mi"),
    ols = calc_joint_bisgz(r_probs, pseudo_vf$turnout, method="ols"),
    
    model = calc_joint_model(fit, "global", 0.5, p_r),
    # credible interval
    model_low = calc_joint_model(fit, "global", 0.05, p_r),
    model_high = calc_joint_model(fit, "global", 0.95, p_r)
)
```

To see what this looks like, we'll compare the true turnout-race distribution to our best guess from the model.

```{r}
print(xr$true)
print(xr$model)
```

We can see the agreement is quite good.
To get a more quantitative measurement of this, we can measure the [total variation distance](https://en.wikipedia.org/wiki/Total_variation_distance_of_probability_measures) between each of our estimates and the true distribution.
Smaller values are better.

```{r}
eval_joints(xr$true, "tv",
            weight = xr$weight,
            thresh = xr$thresh,
            mi = xr$mi,
            ols = xr$ols,
            model = xr$model)
```

The `birdie` methodology meaningfully improves on the other BISG estimators.
-->
